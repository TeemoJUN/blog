## Caffeine VS Guava

1. 强引用（Strong Reference）；不回收
2. 软引用（Soft Reference） ；在内存不足的时候，回收
3. 弱引用(Weak Reference)；遇到垃圾回收启用，就死
4. 虚引用(Phantom Reference)；随时都可能会被回收，当试图通过虚引用的get()方法取得强引用时，总会失败。并且虚引用必须和引用队列一起使用，它的作用在于跟踪垃圾回收过程

+ 当引用被回收是，会将它放入 `ReferenceQueue` 可以用它跟踪对象的收过程



### Guava cache


```java
/**
   * Creates a new, empty map with the specified strategy, initial capacity and concurrency level.
   */
  LocalCache(
      CacheBuilder<? super K, ? super V> builder, @Nullable CacheLoader<? super K, V> loader) {

    //并发程度，控制segment的个数
    concurrencyLevel = Math.min(builder.getConcurrencyLevel(), MAX_SEGMENTS);
        //键的引用强度
    keyStrength = builder.getKeyStrength();
    //值的强度
    valueStrength = builder.getValueStrength();
    //复写键的比较
    keyEquivalence = builder.getKeyEquivalence();
    //值的比较
    valueEquivalence = builder.getValueEquivalence();
    ///最大权重,weigher为null那么maxWeight=maxsize
    maxWeight = builder.getMaximumWeight();
    //计算权重的方法
    weigher = builder.getWeigher();
    //lastAccess之后多长时间删除
    expireAfterAccessNanos = builder.getExpireAfterAccessNanos();
    //在写入后长时间之后删除
    expireAfterWriteNanos = builder.getExpireAfterWriteNanos();
    //刷新的时间间隔
    refreshNanos = builder.getRefreshNanos();
    //entry删除之后的Listener
    removalListener = builder.getRemovalListener();
    //删除监听的队列
    removalNotificationQueue =
        (removalListener == NullListener.INSTANCE)
            ? LocalCache.<RemovalNotification<K, V>>discardingQueue()
            : new ConcurrentLinkedQueue<RemovalNotification<K, V>>();
    //时钟
    ticker = builder.getTicker(recordsTime());
    //创建Entry的Factory
    entryFactory = EntryFactory.getFactory(keyStrength, usesAccessEntries(), usesWriteEntries());
     //缓存的状态统计器，用于统计缓存命中率等
    globalStatsCounter = builder.getStatsCounterSupplier().get();
    //加载数据的Loader
    defaultLoader = loader;
    //初始化HashTable的容量
    int initialCapacity = Math.min(builder.getInitialCapacity(), MAXIMUM_CAPACITY);
    //没有设置权重设置但是有maxsize的设置，那么需要减小容量的设置
    if (evictsBySize() && !customWeigher()) {
      initialCapacity = (int) Math.min(initialCapacity, maxWeight);
    }

    // Find the lowest power-of-two segmentCount that exceeds concurrencyLevel, unless
    // maximumSize/Weight is specified in which case ensure that each segment gets at least 10
    // entries. The special casing for size-based eviction is only necessary because that eviction
    // happens per segment instead of globally, so too many segments compared to the maximum size
    // will result in random eviction behavior.
    //类似于ConcurentHashMap
    int segmentShift = 0;//seg的掩码
    int segmentCount = 1;//seg的个数
    //如果seg的个数事故小于并发度的
    //初始化并发度为4,默认的maxWeight是-1，默认是不驱逐
    while (segmentCount < concurrencyLevel && (!evictsBySize() || segmentCount * 20 <= maxWeight)) {
      ++segmentShift;
      segmentCount <<= 1;
    }
    this.segmentShift = 32 - segmentShift;
    segmentMask = segmentCount - 1;

    this.segments = newSegmentArray(segmentCount);

    int segmentCapacity = initialCapacity / segmentCount;
    if (segmentCapacity * segmentCount < initialCapacity) {
      ++segmentCapacity;
    }

    int segmentSize = 1;
    while (segmentSize < segmentCapacity) {
      segmentSize <<= 1;
    }
    //默认不驱逐
    if (evictsBySize()) {
      // Ensure sum of segment max weights = overall max weights
      long maxSegmentWeight = maxWeight / segmentCount + 1;
      long remainder = maxWeight % segmentCount;
      for (int i = 0; i < this.segments.length; ++i) {
        if (i == remainder) {
          maxSegmentWeight--;
        }
        this.segments[i] =
            createSegment(segmentSize, maxSegmentWeight, builder.getStatsCounterSupplier().get());
      }
    } else {
         //为每一个Segment进行初始化
      for (int i = 0; i < this.segments.length; ++i) {
        this.segments[i] =
            createSegment(segmentSize, UNSET_INT, builder.getStatsCounterSupplier().get());
      }
    }
  }
```

```java
  @Override
  public @Nullable V get(@Nullable Object key) {
    if (key == null) {
      return null;
    }
    int hash = hash(key);//segmentFor 查询所在的段，然后在查询具体值
    return segmentFor(hash).get(key, hash);
  }

   @Nullable
    V get(Object key, int hash) {
      try {
        if (count != 0) { // read-volatile
          long now = map.ticker.read();
          ReferenceEntry<K, V> e = getLiveEntry(key, hash, now);//查询存活的entry
          if (e == null) {
            return null;
          }

          V value = e.getValueReference().get();
          if (value != null) {//如果查询到了
            recordRead(e, now);//并把它放入到recencyQueue 中
            return scheduleRefresh(e, e.getKey(), hash, value, now, map.defaultLoader);//刷新segment
          }
          tryDrainReferenceQueues();//清除引用
        }
        return null;
      } finally {
        postReadCleanup();//执行善后的清理工作
      }
    }

    @Nullable
    ReferenceEntry<K, V> getLiveEntry(Object key, int hash, long now) {
      ReferenceEntry<K, V> e = getEntry(key, hash);
      if (e == null) {
        return null;
      } else if (map.isExpired(e, now)) {
        tryExpireEntries(now);
        return null;
      }
      return e;
    }

    @Nullable
    ReferenceEntry<K, V> getEntry(Object key, int hash) {
      for (ReferenceEntry<K, V> e = getFirst(hash); e != null; e = e.getNext()) {
        if (e.getHash() != hash) {
          continue;
        }

        K entryKey = e.getKey();
        if (entryKey == null) {
          tryDrainReferenceQueues();
          continue;
        }

        if (map.keyEquivalence.equivalent(key, entryKey)) {
          return e;
        }
      }

      return null;
    }
```
* 每一次读写时都会执行
+ runLockedCleanup(now);  
+ runUnlockedCleanup();

```java 
void runLockedCleanup(long now) {
      if (tryLock()) {
        try {
          drainReferenceQueues(); //清理键，或者，值的引用,因为当时虚引用，或者时软引用时，里面维护了一个两个引用列表，当发生GC时，被清理的键或者值就会放到这里面去
          expireEntries(now); // calls drainRecencyQueue 清理 accessQueue writeQueue 里面的东西
          readCount.set(0); //segment回归到原来的
        } finally {
          unlock();
        }
      }
    }
```

``` java 
void runUnlockedCleanup() {
      // locked cleanup may generate notifications we can send unlocked
      if (!isHeldByCurrentThread()) {
        map.processPendingNotifications();//执行移除的通知之类的
      }
    }
```

|Queue|作用|
|:--:|:--:|
|accessQueue|访问队列|
|writeQueue|写入队列|
|recencyQueue|最近访问队列|

+ 这些queue都在Segment里面的，用来控制segment的对象的。且都是循环队列。


+ Guava cache 类似于jdk7的ConcurrentHashMap,其内部的segment.其内部包含引用的键值，和三个循环对列。和两个引用对列.当数据被GC时，会在引用列里面，所以几乎每一个操作都需要去执行清理工作。三个循环队列时用来。在返回时
























